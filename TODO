- latent_vector 나 weight 를 파일로 저장해두고 활용하여 모델 성능이나 확장성을 늘릴 수 있을까?
    사람이 뚜렷하지 않은 기억을 깊이 감춰두거나 회상하는 것 처럼...
    혹은 책이나 자료를 보고 흐릿한 지식을 보충하는 것처럼

- 언어 전처리 시에 의미를 기반으로 한 보다 근본적인 전처리로 문자 부호에 독립된 처리를 할 수 있을까?
    단어 의미를 latent vector 로 자동으로 학습하도록 신경망 설계를 해볼것

- 사람이 언어를 받아들일 때에는 글자 그대로 받아들이는게 아니라 읽어봄(소리로 받아들임)
그리고 자주 접한 글자와 아닌 글자가 있음.
사람은 처음 본 글자는 읽어보려고(tts 생성) 함.
이것은 즉 글자에 대응하는 음성 데이터를 어디에 저장하고 있다는 것.
- 어떤 단어를 배운다는 것은 그것이 ? 에서 시작해서 점차 다른 관점의 다른 평가를 쌓아가는 것.