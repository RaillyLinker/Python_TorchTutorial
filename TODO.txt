- latent_vector 나 weight 를 파일로 저장해두고 활용하여 모델 성능이나 확장성을 늘릴 수 있을까?
    사람이 뚜렷하지 않은 기억을 깊이 감춰두거나 회상하는 것 처럼...
    혹은 책이나 자료를 보고 흐릿한 지식을 보충하는 것처럼

- 언어 전처리 시에 의미를 기반으로 한 보다 근본적인 전처리로 문자 부호에 독립된 처리를 할 수 있을까?
    단어 의미를 latent vector 로 자동으로 학습하도록 신경망 설계를 해볼것

- 사람이 언어를 받아들일 때에는 글자 그대로 받아들이는게 아니라 읽어봄(소리로 받아들임)
    그리고 자주 접한 글자와 아닌 글자가 있음.
    사람은 처음 본 글자는 읽어보려고(tts 생성) 함.
    이것은 즉 글자에 대응하는 음성 데이터를 어디에 저장하고 있다는 것.

- 어떤 단어를 배운다는 것은 그것이 ? 에서 시작해서 점차 다른 관점의 다른 평가를 쌓아가는 것.

- 하위 단어 토크나이징이 아니라 글자단위로 받아서 어텐션을 적용할수 있을지...
    글자 시퀀스를 시계열로 받아서 이것으로 클러스터링을 하고 그 결과를 다시 입력값으로 입력하여 자연어 처리

- 튜토리얼 작성이 끝나면 쓸만한 기술들을 추려서 개발 템플릿 만들기

- 미완성 : 4(통계 관련), 25(워드피스), 32, 34

- gensim save load 부분 다시 보고 개선하기