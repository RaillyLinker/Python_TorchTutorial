import torch
from torch import nn

"""
[장단기 메모리(Long Short-Term Memory, LSTM)]
- 앞서 정리한 RNN을 가장 단순한 형태의 RNN이라고 하여 바닐라 RNN(Vanilla RNN)이라고 합니다. 
    바닐라 RNN 은 등장 직후 자연어 처리 분야를 딥러닝을 통해 정복할 수 있을 것이라는 희망을 보여주었고, 
    바로 자연어 처리의 주류가 되었습니다. 
    이후 바닐라 RNN의 한계를 극복하기 위한 다양한 RNN의 변형이 나왔습니다. 
    LSTM도 그 중 하나입니다.
    
- 바닐라 RNN의 한계
    바닐라 RNN은 비교적 짧은 시퀀스(sequence)에 대해서만 효과를 보이는 단점이 있습니다. 
    RNN 정리글에도 설명하였듯, 바닐라 RNN의 시점(time step)이 길어질 수록 앞의 정보가 뒤로 충분히 전달되지 못하는 현상이 발생하기 때문입니다.
    이를 장기 의존성 문제(the problem of Long-Term Dependencies)라고 합니다.
    
- LSTM 의 구조
    바닐라 RNN 의 구조를 간단하게 정리하면,
    입력값 & 히든 스테이트 -> 인공신경망 레이어 -> 출력값 & 새로운 히든 스테이트
    라고 할 수 있습니다.
    
    전통적인 RNN의 이러한 단점을 보완한 RNN의 일종을 장단기 메모리(Long Short-Term Memory)라고 하며, 줄여서 LSTM이라고 합니다. 
    LSTM은 은닉층의 메모리 셀에 입력 게이트, 망각 게이트, 출력 게이트를 추가하여 불필요한 기억을 지우고, 기억해야할 것들을 정합니다. 
    요약하면 LSTM은 은닉 상태(hidden state)를 계산하는 식이 전통적인 RNN보다 조금 더 복잡해졌으며 셀 상태(cell state)라는 값을 추가하였습니다.
     
    입력값 & 히든 스테이트 & 셀 스테이트 -> 인공신경망 레이어 -> 출력값 & 새로운 히든 스테이트 & 새로운 셀 스테이트
    
    라는 구조로 이루어지며, 바닐라 RNN 에서 셀 스테이트라는 개념이 추가된 것입니다.
    
    아래의 구조 상세 설명은 인터넷에서 LSTM 구조 도식을 보며 읽으시면 좋습니다.
    
- 셀 상태 역시, 히든 스테이트와 같이 이전에 배운 은닉 상태처럼 이전 시점의 셀 상태가 다음 시점의 셀 상태를 구하기 위한 입력으로서 사용됩니다.
    은닉 상태값과 셀 상태값을 구하기 위해서 새로 추가 된 3개의 게이트를 사용합니다. 
    각 게이트는 삭제 게이트, 입력 게이트, 출력 게이트라고 부르며 이 3개의 게이트에는 공통적으로 시그모이드 함수가 존재합니다. 
    시그모이드 함수를 지나면 0과 1사이의 값이 나오게 되는데 이 값들을 가지고 게이트를 조절합니다.
    마치 벨브를 잠그고 열듯이, 해당 단어가 해당 시점에 유의한지 아닌지에 대한 판단을 가지고, 이번 연산을 현재 분석에 반영할지,
    다음 스테이트에 전달할지에 대한 자기 자신을 규제하는 학습을 하게 되는 것입니다.
    
- 입력 게이트 설명
    LSTM 을 구성하는 게이트들 중에 먼저 입력 게이트를 확인하겠습니다.
    이는 현재 입력받은 x 값과 히든 스테이트를 가지고 tanh 활성화 함수로 바닐라 RNN 과 같이 연산을 진행하는 것입니다.(바닐라와 동일)
    한가지 다른점으로는, x 값과 히든 스테이트에 벨브 역할을 하는 시그모이드를 달아서 해당 입력값이 입력할 가치가 있는지 아닌지에 대한 판별을 하는 것입니다.
    tanh 분석 결과에 0~1 사이의 벨브값이 곱해져서 tanh 셀 스테이트에 더해지게 됩니다.
    
- 삭제 게이트
    이 게이트는 이전 셀 스테이트의 영향력을 조절하는 역할을 합니다.
    히든 스테이트와 x 값으로 계산된 시그모이드 벨브값을 셀 스테이트에 곱하여, 기존까지 축적된 셀 스테이트의 영향력을 조절합니다.
    
- 장기 상태(셀 상태)
    먼저 삭제 게이트가 실행되어 셀 스테이트에 곱해지고, 이번 입력 게이트의 값이 계산되어 셀 스테이트에 더해졌습니다.
    셀 스테이트의 갱신은 한번의 셀 연산에서 이 두개의 게이트의 영향을 받게 됩니다.
    이 구조에서 본다면 셀 상태라는 것이, 처음부터 현재까지의 메모리를 담은 장기 상태값이라는 것을 알 수 있습니다.
    
- 출력 게이트
    위에서 장기 상태값인 셀 스테이트를 현재 값의 영향력에 따라 갱신하였습니다.
    이제 이러한 장기 메모리를 바탕으로 현재의 출력값과 히든 스테이트를 만드는 출력 게이트를 실행하게 됩니다.
    출력 게이트는 앞서 입력 게이트까지 적용된 셀 스테이트를 가지고 tanh 를 실행시킵니다.
    즉, 바닐라 RNN 과 비교하자면, 현재까지의 장기적 메모리를 지닌 셀 스테이트가 입력값이 되는 것인데,
    이렇게 만들어진 출력값이 존재하면 여기에 또 벨브를 답니다.
    히든 스테이트와 x 값을 사용하여 시그모이드를 한 벨브의 값을 또 구하여, 장기 메모리로 구한 데이터와 곱하면 됩니다.
    이 값이 바로 LSTM 셀의 출력값이자, 단기 메모리인 히든 스테이트라고 할 수 있습니다.
    
- 위와같이 정리한 내용을 보자면,
    LSTM 의 핵심은 RNN 의 핵심인 "이전 정보의 흐름" 에 벨브를 단 것이라고 할 수 있습니다.
    현재 들어온 단어로 기존 단어의 흐름을 평가하는 형태인데,
    추후 정리할 현시점 자연어 처리의 최강자인 GPT 의 근본인 Transformer 에서는 이에 대조하여,
    Attention is all you need 라는 논문으로, 정보의 흐름은 필요치 않고, 각 정보 시퀀스별 평가를 내리는
    어텐션의 중요성을 강조하며 자연어 처리, 시계열 처리뿐 아니라 AGI 에 다가가는 근본 형태를 만들어냈습니다.

- 아래 코드는 torch 에서 제공하는 LSTM 레이어를 생성하여 순전파 하는 예시 입니다.
"""

input_size = 128
output_size = 256
num_layers = 3
bidirectional = True

model = nn.LSTM(
    input_size=input_size,
    hidden_size=output_size,
    num_layers=num_layers,
    batch_first=True,
    bidirectional=bidirectional,
)

batch_size = 4
sequence_len = 6

inputs = torch.randn(batch_size, sequence_len, input_size)
h_0 = torch.rand(
    num_layers * (int(bidirectional) + 1),
    batch_size,
    output_size,
)
c_0 = torch.rand(num_layers * (int(bidirectional) + 1), batch_size, output_size)

outputs, (h_n, c_n) = model(inputs, (h_0, c_0))

print(outputs.shape)  # 출력값 형태
print(h_n.shape)  # 히든 스테이트 형태
print(c_n.shape)  # 셀 스테이트 형태
